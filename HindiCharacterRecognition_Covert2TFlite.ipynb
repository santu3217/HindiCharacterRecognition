{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8rnE1FDq8Qcr"
   },
   "outputs": [],
   "source": [
    "# Dounloading the Dataset\n",
    "!wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.81 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-GB,en-US;q=0.9,en;q=0.8\" --header=\"Referer: https://www.kaggle.com/\" \"https://storage.googleapis.com/kaggle-data-sets/1582264/2603511/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20220209%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20220209T112913Z&X-Goog-Expires=259199&X-Goog-SignedHeaders=host&X-Goog-Signature=44b3e18fc9f08d18f8665050cc2f95350d90d0d3e699e295a02ec312945f8ccdedd3877010849de40b43941cb1f327cc179811ec0cf4d16775a0a416e36565e52a408daf6e7bf9eb4671c89991709d38b289c61d4342c050ce9862f81619e4fe8cd2a9cbbc11835060a58a37cdd489fe42fd0219f329a2fb3e0717ae5758fcec2aa8d39bb320857c9437b63e1904c25c130c107c3376d59662fe29d2fa3ca7f7d3cdb00271223b040902fea79cdbd7d3667008275dacb369a38a46b7c947eedaae40c973c9a14cd34fcac2bc8d9b9ab11698184e9a33d5b1236f57cc901179b5fdc5aa1c779e064271fed77f5e00af7cd360054550fc1663f0ba3e68dc05c7c5\" -c -O 'archive.zip'\n",
    "!unzip archive.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7flagfYy5qif"
   },
   "outputs": [],
   "source": [
    "# Importing the Required Libraries\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "from sys import getsizeof\n",
    "from tensorflow.keras.layers import *\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gitNK4da5w_A"
   },
   "outputs": [],
   "source": [
    "def get_size(file_path):\n",
    "  \"\"\"\"Prints the size of the file in MB\"\"\"\n",
    "  size = os.path.getsize(file_path)\n",
    "\n",
    "  print('File size: ' + str(round(size/(1024 * 1024),3)) + ' Megabytes')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M3Ej_i7_8uFg",
    "outputId": "0140d577-6145-4a07-cb8c-c87d81125d45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13800 images belonging to 46 classes.\n"
     ]
    }
   ],
   "source": [
    "# Initializing and loading the data using ImageDataGenerator\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    'DevanagariHandwrittenCharacterDataset/Test',\n",
    "    target_size=(32, 32),\n",
    "    batch_size=64,\n",
    "    seed = 7,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XY0mq3Hf5w7s"
   },
   "outputs": [],
   "source": [
    "# Loading the trained TF Model\n",
    "Model = tf.keras.models.load_model('/content/drive/MyDrive/CS2_Model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "btvRx2Bg5w4H",
    "outputId": "a25c8bc8-74b5-4650-a0e1-e0db003c0381"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216/216 [==============================] - 29s 130ms/step - loss: 0.1285 - accuracy: 0.9606\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.12848027050495148, 0.9605796933174133]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating the Model performance\n",
    "Model.evaluate(validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3ZwXaeZkXedx",
    "outputId": "f756bc53-c5e9-45b2-94ed-c5628c6a87d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy of the Model is 96.0%\n"
     ]
    }
   ],
   "source": [
    "# Printing the Accuracy of the Model\n",
    "print('The Accuracy of the Model is 96.0%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jwjpb7QWAvFO",
    "outputId": "96e6b2c4-9c80-4817-b661-50d9a0fdf43d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size: 150.4 Megabytes\n"
     ]
    }
   ],
   "source": [
    "# Printing the size of the File\n",
    "get_size('/content/drive/MyDrive/CS2_Model1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xT4Z6kZS88xJ"
   },
   "source": [
    "# TF Lite Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mhjUZ2gH5w0H",
    "outputId": "bcf0aa76-5aec-4f50-f580-bab29f75172f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Optimization option OPTIMIZE_FOR_SIZE is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp3yvouc66/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp3yvouc66/assets\n",
      "WARNING:absl:Optimization option OPTIMIZE_FOR_SIZE is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n",
      "WARNING:absl:Optimization option OPTIMIZE_FOR_SIZE is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
     ]
    }
   ],
   "source": [
    "# Converting the Tensorflow Model to Tensorflow Lite Model\n",
    "tf_lite_converter = tf.lite.TFLiteConverter.from_keras_model(Model)\n",
    "tf_lite_converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
    "\n",
    "TF_Lite_Model = tf_lite_converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EVAEu3xM5wwx",
    "outputId": "ba9313f8-9413-4e6d-9fab-59b363a50fdc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13149456"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving the Tensorflow Lite model in \"TF_Lite_Model.tflite\" file\n",
    "open('TF_Lite_Model.tflite','wb').write(TF_Lite_Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RZGxG-F8_dL0",
    "outputId": "8f736ab5-86b8-4e32-c679-d05462c7a4f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size: 12.54 Megabytes\n"
     ]
    }
   ],
   "source": [
    "# Printing the size of the TF Lite model\n",
    "get_size('TF_Lite_Model.tflite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kW7jqptu_c5T",
    "outputId": "58540cad-d806-4574-ec3b-6510601d8fbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Input Shape is  [ 1 32 32  1]\n",
      "The Input Data Type is  <class 'numpy.float32'>\n",
      "The Output Shape is  [ 1 46]\n",
      "The Output Data Type is  <class 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "# Checking the Input and Output shapes \n",
    "interpreter = tf.lite.Interpreter(model_path='TF_Lite_Model.tflite')\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print('The Input Shape is ', input_details[0]['shape'])\n",
    "print('The Input Data Type is ', input_details[0]['dtype'])\n",
    "print('The Output Shape is ', output_details[0]['shape'])\n",
    "print('The Output Data Type is ', output_details[0]['dtype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CUkXLLHHF5sa"
   },
   "outputs": [],
   "source": [
    "# Resizing the input and output shapes \n",
    "interpreter.resize_tensor_input(input_details[0]['index'], (64, 32, 32, 1))\n",
    "interpreter.resize_tensor_input(output_details[0]['index'], (64, 46))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XwBtGp05G9kM",
    "outputId": "6900319f-6010-49a9-a8f5-fc9d516a4b1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Input Shape is  [64 32 32  1]\n",
      "The Input Data Type is  <class 'numpy.float32'>\n",
      "The Output Shape is  [64 46]\n",
      "The Output Data Type is  <class 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "# Checking the Input and Output shapes after resizing\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print('The Input Shape is ', input_details[0]['shape'])\n",
    "print('The Input Data Type is ', input_details[0]['dtype'])\n",
    "print('The Output Shape is ', output_details[0]['shape'])\n",
    "print('The Output Data Type is ', output_details[0]['dtype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "in7oldWiKkAc"
   },
   "outputs": [],
   "source": [
    "# Evaluating the TF Lite model Performance\n",
    "actual_class = []\n",
    "predicted_class = []\n",
    "\n",
    "for data, label in validation_generator:\n",
    "  if (len(label) < validation_generator.batch_size) and (len(predicted_class) >= 13700):\n",
    "    break\n",
    "\n",
    "  actual_class.extend(np.argmax(label,axis=-1))\n",
    "  interpreter.allocate_tensors()\n",
    "  interpreter.set_tensor(input_details[0]['index'], data)\n",
    "  interpreter.invoke()\n",
    "  tflite_model_predictions = interpreter.get_tensor(output_details[0]['index'])\n",
    "  prediction_classes = np.argmax(tflite_model_predictions, axis=1)\n",
    "  predicted_class.extend(prediction_classes.tolist())\n",
    "\n",
    "    # We have to break out from the generator when we've processed \n",
    "    # the entire once (otherwise we would end up with duplicates). \n",
    "  if (len(label) < validation_generator.batch_size) and :\n",
    "      break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vFq2Fkw8HUyz",
    "outputId": "57de06bb-2b89-424a-bca7-3d657e00814a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy of the TF Lite Model is 96.2%\n"
     ]
    }
   ],
   "source": [
    "# Printing the Accuracy of the TF Lite Model\n",
    "accuracy = accuracy_score(predicted_class, actual_class)\n",
    "print('The Accuracy of the TF Lite Model is {:.1f}%'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S1SzB6PiOveN"
   },
   "source": [
    "By converting our model from Tensorflow to Tensorflow Lite we could decrease the size of the file from 150 MB to 12 MB with no drop in the performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-_ZAgXIEPC8v"
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TF_Lite_Model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
